{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://NeuronUser:****@pip.repos.beta.neuron.annapurna.aws.a2z.com\n",
      "Collecting numpy<=1.18.2,>=1.13.3\n",
      "  Downloading numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.5\n",
      "  Downloading torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0 MB)\n",
      "\u001b[K     |█████████████▍                  | 313.9 MB 136.6 MB/s eta 0:00:04     |████████▌                       | 199.5 MB 163.7 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████▍   | 667.8 MB 129.4 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting neuron-cc[tensorflow]>=1.0.16861.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/neuron-cc/neuron_cc-1.0.20600.0%2B0.b426b885f-cp36-cp36m-linux_x86_64.whl (45.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.0 MB 87.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch-neuron\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/torch-neuron/torch_neuron-1.5.1.1.0.1705.0-py3-none-linux_x86_64.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 84.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch-neuron-base\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/torch-neuron-base/torch_neuron_base-1.5.1.1.0.337.0-cp36-cp36m-linux_x86_64.whl (77.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 77.5 MB 1.8 MB/s eta 0:00:0101     |███████▏                        | 17.4 MB 110.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers==2.5.1\n",
      "  Downloading transformers-2.5.1-py3-none-any.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 120.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 84.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dmlc-tvm==1.0.3133.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-tvm/dmlc_tvm-1.0.3133.0%2B0-cp36-cp36m-linux_x86_64.whl (72.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 72.8 MB 89.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting inferentia-hwm==1.0.1835.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/inferentia-hwm/inferentia_hwm-1.0.1835.0%2B0-cp36-cp36m-linux_x86_64.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 97.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy<=1.3.2\n",
      "  Downloading scipy-1.3.2-cp36-cp36m-manylinux1_x86_64.whl (25.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2 MB 75.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting islpy==2018.2\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/islpy/islpy-2018.2%2Baws2018.x.576.0.bld0-cp36-cp36m-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 87.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dmlc-topi==1.0.3133.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-topi/dmlc_topi-1.0.3133.0%2B0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 70.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx<=2.4\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 74.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dmlc-nnvm==1.0.3133.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-nnvm/dmlc_nnvm-1.0.3133.0%2B0-py3-none-any.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 106.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow<=1.15.0; extra == \"tensorflow\"\n",
      "  Downloading tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3 MB)\n",
      "\u001b[K     |██████████████████████▍         | 288.9 MB 147.6 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "  Downloading tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.14.63.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 107.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 103.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 81.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 126.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 93.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 29.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting attrs\n",
      "  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 93.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting decorator\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting cffi>=1.1.0\n",
      "  Downloading cffi-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\n",
      "\u001b[K     |████████████████████████████████| 400 kB 123.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 57.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 97.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 63.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 119.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 88.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 72.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Downloading wheel-0.35.1-py2.py3-none-any.whl (33 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 122.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.18.0,>=1.17.63\n",
      "  Downloading botocore-1.17.63-py2.py3-none-any.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 107.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 59.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 122.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 121.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 117.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 121.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 98.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 122.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-50.3.0-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 117.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 60.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 122.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 115.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 122.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 120.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Building wheels for collected packages: future, boto3, sacremoses, gast, termcolor, wrapt\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=ec3421f8bb0b56c9a97916d7db8aa79a25215b0b6a8c7d0ba3b9637649459569\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "  Building wheel for boto3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for boto3: filename=boto3-1.14.63-py2.py3-none-any.whl size=127856 sha256=2daccb8a3f81d7b965a6433f6e5efd23d34a2292a2aba114a210b8556993cccd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/91/d8/58/cad57749ce085357c346659ec006f301180d83bc5c25447f43\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=4be03cd2d4b5b92926190c94ec201ecac0b956277322e0b9d1464ecf9c2cca57\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=2c5de36d6320b3c3a42d5b57cac025e76813147c4dc100732f8fc043b1b79fa7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=b1dff34ccb99358800aa034a9ae54ceedca92cd68eec1ba79ee818d8942c4dc5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66651 sha256=2c02965314007cbaa85941ff4ddfe915c4201a18e213168ed3cda8f62d56b882\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukb8p9z3/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built future boto3 sacremoses gast termcolor wrapt\n",
      "\u001b[31mERROR: spyder 4.1.4 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 4.1.4 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.136 has requirement botocore==1.17.59, but you'll have botocore 1.17.63 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, future, torch, attrs, decorator, dmlc-tvm, inferentia-hwm, scipy, pycparser, cffi, six, islpy, dmlc-topi, networkx, dmlc-nnvm, gast, google-pasta, keras-preprocessing, opt-einsum, setuptools, protobuf, tensorflow-estimator, astor, termcolor, wrapt, h5py, keras-applications, werkzeug, zipp, importlib-metadata, markdown, grpcio, wheel, absl-py, tensorboard, tensorflow, neuron-cc, torch-neuron, torch-neuron-base, tokenizers, python-dateutil, docutils, urllib3, jmespath, botocore, s3transfer, boto3, tqdm, filelock, sentencepiece, regex, click, joblib, sacremoses, chardet, certifi, idna, requests, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.2\n",
      "    Uninstalling numpy-1.18.2:\n",
      "      Successfully uninstalled numpy-1.18.2\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.18.2\n",
      "    Uninstalling future-0.18.2:\n",
      "      Successfully uninstalled future-0.18.2\n",
      "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.5.0\n",
      "    Uninstalling torch-1.5.0:\n",
      "      Successfully uninstalled torch-1.5.0\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.2.0\n",
      "    Uninstalling attrs-20.2.0:\n",
      "      Successfully uninstalled attrs-20.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: dmlc-tvm\n",
      "    Found existing installation: dmlc-tvm 1.0.2831.0+0\n",
      "    Uninstalling dmlc-tvm-1.0.2831.0+0:\n",
      "      Successfully uninstalled dmlc-tvm-1.0.2831.0+0\n",
      "  Attempting uninstall: inferentia-hwm\n",
      "    Found existing installation: inferentia-hwm 1.0.1592.0+0\n",
      "    Uninstalling inferentia-hwm-1.0.1592.0+0:\n",
      "      Successfully uninstalled inferentia-hwm-1.0.1592.0+0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.2\n",
      "    Uninstalling scipy-1.3.2:\n",
      "      Successfully uninstalled scipy-1.3.2\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.2\n",
      "    Uninstalling cffi-1.14.2:\n",
      "      Successfully uninstalled cffi-1.14.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: islpy\n",
      "    Found existing installation: islpy 2018.2+aws2018.x.508.0.bld0\n",
      "    Uninstalling islpy-2018.2+aws2018.x.508.0.bld0:\n",
      "      Successfully uninstalled islpy-2018.2+aws2018.x.508.0.bld0\n",
      "  Attempting uninstall: dmlc-topi\n",
      "    Found existing installation: dmlc-topi 1.0.2831.0+0\n",
      "    Uninstalling dmlc-topi-1.0.2831.0+0:\n",
      "      Successfully uninstalled dmlc-topi-1.0.2831.0+0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.4\n",
      "    Uninstalling networkx-2.4:\n",
      "      Successfully uninstalled networkx-2.4\n",
      "  Attempting uninstall: dmlc-nnvm\n",
      "    Found existing installation: dmlc-nnvm 1.0.2831.0+0\n",
      "    Uninstalling dmlc-nnvm-1.0.2831.0+0:\n",
      "      Successfully uninstalled dmlc-nnvm-1.0.2831.0+0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 50.3.0\n",
      "    Uninstalling setuptools-50.3.0:\n",
      "      Successfully uninstalled setuptools-50.3.0\n",
      "\u001b[33m  WARNING: The scripts easy_install and easy_install-3.6 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.13.0\n",
      "    Uninstalling protobuf-3.13.0:\n",
      "      Successfully uninstalled protobuf-3.13.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: keras-applications\n",
      "    Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.1.0\n",
      "    Uninstalling zipp-3.1.0:\n",
      "      Successfully uninstalled zipp-3.1.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.2.2\n",
      "    Uninstalling Markdown-3.2.2:\n",
      "      Successfully uninstalled Markdown-3.2.2\n",
      "\u001b[33m  WARNING: The script markdown_py is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.35.1\n",
      "    Uninstalling wheel-0.35.1:\n",
      "      Successfully uninstalled wheel-0.35.1\n",
      "\u001b[33m  WARNING: The script wheel is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.10.0\n",
      "    Uninstalling absl-py-0.10.0:\n",
      "      Successfully uninstalled absl-py-0.10.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: neuron-cc\n",
      "    Found existing installation: neuron-cc 1.0.18001.0+0.5312e6a21\n",
      "    Uninstalling neuron-cc-1.0.18001.0+0.5312e6a21:\n",
      "      Successfully uninstalled neuron-cc-1.0.18001.0+0.5312e6a21\n",
      "\u001b[33m  WARNING: The script neuron-cc is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: torch-neuron\n",
      "    Found existing installation: torch-neuron 1.5.1.1.0.1532.0\n",
      "    Uninstalling torch-neuron-1.5.1.1.0.1532.0:\n",
      "      Successfully uninstalled torch-neuron-1.5.1.1.0.1532.0\n",
      "  Attempting uninstall: torch-neuron-base\n",
      "    Found existing installation: torch-neuron-base 1.5.1.1.0.298.0\n",
      "    Uninstalling torch-neuron-base-1.5.1.1.0.298.0:\n",
      "      Successfully uninstalled torch-neuron-base-1.5.1.1.0.298.0\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.15.2\n",
      "    Uninstalling docutils-0.15.2:\n",
      "      Successfully uninstalled docutils-0.15.2\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.10\n",
      "    Uninstalling urllib3-1.25.10:\n",
      "      Successfully uninstalled urllib3-1.25.10\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 0.10.0\n",
      "    Uninstalling jmespath-0.10.0:\n",
      "      Successfully uninstalled jmespath-0.10.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.17.63\n",
      "    Uninstalling botocore-1.17.63:\n",
      "      Successfully uninstalled botocore-1.17.63\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.3\n",
      "    Uninstalling s3transfer-0.3.3:\n",
      "      Successfully uninstalled s3transfer-0.3.3\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.14.63\n",
      "    Uninstalling boto3-1.14.63:\n",
      "      Successfully uninstalled boto3-1.14.63\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.49.0\n",
      "    Uninstalling tqdm-4.49.0:\n",
      "      Successfully uninstalled tqdm-4.49.0\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.0.12\n",
      "    Uninstalling filelock-3.0.12:\n",
      "      Successfully uninstalled filelock-3.0.12\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.91\n",
      "    Uninstalling sentencepiece-0.1.91:\n",
      "      Successfully uninstalled sentencepiece-0.1.91\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2020.7.14\n",
      "    Uninstalling regex-2020.7.14:\n",
      "      Successfully uninstalled regex-2020.7.14\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.16.0\n",
      "    Uninstalling joblib-0.16.0:\n",
      "      Successfully uninstalled joblib-0.16.0\n",
      "  Attempting uninstall: sacremoses\n",
      "    Found existing installation: sacremoses 0.0.43\n",
      "    Uninstalling sacremoses-0.0.43:\n",
      "      Successfully uninstalled sacremoses-0.0.43\n",
      "\u001b[33m  WARNING: The script sacremoses is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "\u001b[33m  WARNING: The script chardetect is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.6.20\n",
      "    Uninstalling certifi-2020.6.20:\n",
      "      Successfully uninstalled certifi-2020.6.20\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.24.0\n",
      "    Uninstalling requests-2.24.0:\n",
      "      Successfully uninstalled requests-2.24.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.5.1\n",
      "    Uninstalling transformers-2.5.1:\n",
      "      Successfully uninstalled transformers-2.5.1\n",
      "Successfully installed absl-py-0.10.0 astor-0.8.1 attrs-20.2.0 boto3-1.14.63 botocore-1.17.63 certifi-2020.6.20 cffi-1.14.2 chardet-3.0.4 click-7.1.2 decorator-4.4.2 dmlc-nnvm-1.0.3133.0+0 dmlc-topi-1.0.3133.0+0 dmlc-tvm-1.0.3133.0+0 docutils-0.15.2 filelock-3.0.12 future-0.18.2 gast-0.2.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 importlib-metadata-1.7.0 inferentia-hwm-1.0.1835.0+0 islpy-2018.2+aws2018.x.576.0.bld0 jmespath-0.10.0 joblib-0.16.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.2.2 networkx-2.4 neuron-cc-1.0.20600.0+0.b426b885f numpy-1.18.2 opt-einsum-3.3.0 protobuf-3.13.0 pycparser-2.20 python-dateutil-2.8.1 regex-2020.7.14 requests-2.24.0 s3transfer-0.3.3 sacremoses-0.0.43 scipy-1.3.2 sentencepiece-0.1.91 setuptools-50.3.0 six-1.15.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-1.1.0 tokenizers-0.5.2 torch-1.5.0 torch-neuron-1.5.1.1.0.1705.0 torch-neuron-base-1.5.1.1.0.337.0 tqdm-4.49.0 transformers-2.5.1 urllib3-1.25.10 werkzeug-1.0.1 wheel-0.35.1 wrapt-1.12.1 zipp-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --user --upgrade --force-reinstall --no-cache-dir 'numpy<=1.18.2,>=1.13.3' torch==1.5 'neuron-cc[tensorflow]>=1.0.16861.0' torch-neuron torch-neuron-base transformers==2.5.1 --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://NeuronUser:****@pip.repos.beta.neuron.annapurna.aws.a2z.com\n",
      "Collecting neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/neuron-cc/neuron_cc-1.0.19964.0%2B0.e46902ca9-cp36-cp36m-linux_x86_64.whl (48.2 MB)\n",
      "Requirement already up-to-date: torch-neuron in /home/ec2-user/.local/lib/python3.6/site-packages (1.5.1.1.0.1705.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx<=2.4 in /home/ec2-user/.local/lib/python3.6/site-packages (from neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy<=1.3.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<=1.18.2,>=1.13.3 in /home/ec2-user/.local/lib/python3.6/site-packages (from neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.18.2)\n",
      "Collecting dmlc-nnvm==1.0.3081.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-nnvm/dmlc_nnvm-1.0.3081.0%2B0-py3-none-any.whl (14.8 MB)\n",
      "Collecting dmlc-topi==1.0.3081.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-topi/dmlc_topi-1.0.3081.0%2B0-py3-none-any.whl (1.5 MB)\n",
      "Collecting inferentia-hwm==1.0.1786.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/inferentia-hwm/inferentia_hwm-1.0.1786.0%2B0-cp36-cp36m-linux_x86_64.whl (47 kB)\n",
      "Requirement already satisfied, skipping upgrade: islpy==2018.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (2018.2+aws2018.x.576.0.bld0)\n",
      "Collecting dmlc-tvm==1.0.3081.0\n",
      "  Downloading https://pip.repos.beta.neuron.annapurna.aws.a2z.com/dmlc-tvm/dmlc_tvm-1.0.3081.0%2B0-cp36-cp36m-linux_x86_64.whl (72.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<=1.15.0; extra == \"tensorflow\" in /home/ec2-user/.local/lib/python3.6/site-packages (from neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: torch~=1.5.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from torch-neuron) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from networkx<=2.4->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ec2-user/.local/lib/python3.6/site-packages (from islpy==2018.2->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from islpy==2018.2->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: attrs in /home/ec2-user/.local/lib/python3.6/site-packages (from dmlc-tvm==1.0.3081.0->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (20.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.15.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/ec2-user/.local/lib/python3.6/site-packages (from torch~=1.5.0->torch-neuron) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/ec2-user/.local/lib/python3.6/site-packages (from cffi>=1.1.0->islpy==2018.2->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (2.20)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/ec2-user/.local/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<=1.15.0; extra == \"tensorflow\"->neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9) (3.1.0)\n",
      "Installing collected packages: dmlc-nnvm, inferentia-hwm, dmlc-topi, dmlc-tvm, neuron-cc\n",
      "  Attempting uninstall: dmlc-nnvm\n",
      "    Found existing installation: dmlc-nnvm 1.0.3133.0+0\n",
      "    Uninstalling dmlc-nnvm-1.0.3133.0+0:\n",
      "      Successfully uninstalled dmlc-nnvm-1.0.3133.0+0\n",
      "  Attempting uninstall: inferentia-hwm\n",
      "    Found existing installation: inferentia-hwm 1.0.1835.0+0\n",
      "    Uninstalling inferentia-hwm-1.0.1835.0+0:\n",
      "      Successfully uninstalled inferentia-hwm-1.0.1835.0+0\n",
      "  Attempting uninstall: dmlc-topi\n",
      "    Found existing installation: dmlc-topi 1.0.3133.0+0\n",
      "    Uninstalling dmlc-topi-1.0.3133.0+0:\n",
      "      Successfully uninstalled dmlc-topi-1.0.3133.0+0\n",
      "  Attempting uninstall: dmlc-tvm\n",
      "    Found existing installation: dmlc-tvm 1.0.3133.0+0\n",
      "    Uninstalling dmlc-tvm-1.0.3133.0+0:\n",
      "      Successfully uninstalled dmlc-tvm-1.0.3133.0+0\n",
      "  Attempting uninstall: neuron-cc\n",
      "    Found existing installation: neuron-cc 1.0.20600.0+0.b426b885f\n",
      "    Uninstalling neuron-cc-1.0.20600.0+0.b426b885f:\n",
      "      Successfully uninstalled neuron-cc-1.0.20600.0+0.b426b885f\n",
      "Successfully installed dmlc-nnvm-1.0.3081.0+0 dmlc-topi-1.0.3081.0+0 dmlc-tvm-1.0.3081.0+0 inferentia-hwm-1.0.1786.0+0 neuron-cc-1.0.19964.0+0.e46902ca9\n",
      "Name: neuron-cc\n",
      "Version: 1.0.19964.0+0.e46902ca9\n",
      "Summary: AWS Neuron SDK compiler\n",
      "Home-page: https://aws.amazon.com/machine-learning/inferentia/\n",
      "Author: None\n",
      "Author-email: None\n",
      "License: AWS Neuron Core Software License Agreement\n",
      "Location: /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages\n",
      "Requires: dmlc-tvm, dmlc-nnvm, islpy, scipy, numpy, inferentia-hwm, dmlc-topi, networkx\n",
      "Required-by: \n",
      "Name: torch-neuron\n",
      "Version: 1.5.1.1.0.1705.0\n",
      "Summary: UNKNOWN\n",
      "Home-page: UNKNOWN\n",
      "Author: AWS\n",
      "Author-email: UNKNOWN\n",
      "License: Proprietary\n",
      "Location: /home/ec2-user/.local/lib/python3.6/site-packages\n",
      "Requires: torch\n",
      "Required-by: \n",
      "Name: transformers\n",
      "Version: 2.5.1\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/ec2-user/.local/lib/python3.6/site-packages\n",
      "Requires: tokenizers, sentencepiece, requests, regex, boto3, filelock, sacremoses, tqdm, numpy\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# pip install neuron-cc[tensorflow]==1.0.19964.0+0.e46902ca9 torch-neuron -U --extra-index-url https://NeuronUser:KdKL46JmmWq12KJk@pip.repos.beta.neuron.annapurna.aws.a2z.com\n",
    "pip install neuron-cc[tensorflow]==1.0.18001.0+0.5312e6a21 torch-neuron -U --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "pip show neuron-cc\n",
    "pip show torch-neuron\n",
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.546835528016529\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_neuron\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "sentence1=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "sentence2=\"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    "sentence3=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "cos = torch.nn.CosineSimilarity()\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence1, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "outputs = model(encoded_sentence['input_ids'])\n",
    "s1 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence2, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "outputs = model(encoded_sentence['input_ids'])\n",
    "s2 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "        \n",
    "cos_sim = cos(s1,s2)\n",
    "cosine_measure = cos_sim[0].item()\n",
    "angle_in_radians = math.acos(cosine_measure)\n",
    "print(math.degrees(angle_in_radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentence['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Optimize = None\n",
      "INFO:Neuron:Compiler args type is <class 'list'> value is ['-O2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Use compile_from_neff function\n",
      "-- Use create_runnable function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_runtime.cpp:638: UserWarning: Cannot initialize NeuronCore Group with 1 cores; stopping initialization.\n",
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_op_impl.cpp:52: UserWarning: Neuron runtime cannot be initialized; falling back to CPU execution\n",
      "Tensor output are ** NOT CALCULATED ** during CPU execution and only indicate tensor shape\n",
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_runtime.cpp:638: UserWarning: Cannot initialize NeuronCore Group with 1 cores; stopping initialization.\n",
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_op_impl.cpp:52: UserWarning: Neuron runtime cannot be initialized; falling back to CPU execution\n",
      "Tensor output are ** NOT CALCULATED ** during CPU execution and only indicate tensor shape\n",
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_runtime.cpp:638: UserWarning: Cannot initialize NeuronCore Group with 1 cores; stopping initialization.\n",
      "/opt/workspace/KaenaPyTorchRuntime/neuron_op/neuron_op_impl.cpp:52: UserWarning: Neuron runtime cannot be initialized; falling back to CPU execution\n",
      "Tensor output are ** NOT CALCULATED ** during CPU execution and only indicate tensor shape\n"
     ]
    }
   ],
   "source": [
    "example_inputs = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids']\n",
    "model_neuron = torch.neuron.trace(model, example_inputs, compiler_args=['-O2'], verbose=1, compiler_workdir='./compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sentence1=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "sentence2=\"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    "sentence3=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence1, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_statement = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids']\n",
    "outputs = model_neuron(*input_statement)\n",
    "s1 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence2, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_statement = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids']\n",
    "outputs = model_neuron(*input_statement)\n",
    "s2 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "        \n",
    "cos_sim = cos(s1,s2)\n",
    "cosine_measure = cos_sim[0].item()\n",
    "angle_in_radians = math.acos(cosine_measure)\n",
    "print(math.degrees(angle_in_radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentence1=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "sentence2=\"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    "sentence3=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence1, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "outputs = model(encoded_sentence['input_ids'])\n",
    "s1 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence2, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "outputs = model(encoded_sentence['input_ids'])\n",
    "s2 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "        \n",
    "cos_sim = cos(s1,s2)\n",
    "cosine_measure = cos_sim[0].item()\n",
    "angle_in_radians = math.acos(cosine_measure)\n",
    "print(math.degrees(angle_in_radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neuron.save('neuron_compiled_1_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_again = torch.jit.load('neuron_compiled_1_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentence1=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "sentence2=\"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    "sentence3=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence1, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_statement = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids']\n",
    "outputs = model_again(*input_statement)\n",
    "s1 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence2, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_statement = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids']\n",
    "outputs = model_again(*input_statement)\n",
    "s2 = outputs[1]  # The last hidden-state is the first element of the output tuple\n",
    "        \n",
    "cos_sim = cos(s1,s2)\n",
    "cosine_measure = cos_sim[0].item()\n",
    "angle_in_radians = math.acos(cosine_measure)\n",
    "print(math.degrees(angle_in_radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -czvf model.tar.gz neuron_compiled_1_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 cp model.tar.gz s3://inf1-compiled-model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
