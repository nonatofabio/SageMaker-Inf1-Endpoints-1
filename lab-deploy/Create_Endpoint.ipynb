{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Your model is not compiled. Please compile your model before using Inferentia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "role = sagemaker.session.get_execution_role()\n",
    "\n",
    "model_data='s3://inf1-compiled-bert-model/model.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=model_data, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py',\n",
    "                             image='249828997522.dkr.ecr.us-east-1.amazonaws.com/bert-inf1-serving:latest',\n",
    "                             framework_version='1.5.0',\n",
    "                             enable_cloudwatch_metrics=True)\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.inf1.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import math\n",
    "import numpy as np\n",
    "import io\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pickle \n",
    "\n",
    "def numpy_bytes_serializer(data):\n",
    "    f = io.BytesIO()\n",
    "    np.save(f, data)\n",
    "    f.seek(0)\n",
    "    return f.read()\n",
    "\n",
    "# vnd indicates vendor-specific MIME types, which means they are MIME types that were \n",
    "# introduced by corporate bodies rather than e.g. an Internet consortium.\n",
    "\n",
    "\n",
    "#-predictor.serializer = numpy_bytes_serializer\n",
    "#-predictor.deserializer = csv_serializer\n",
    "\n",
    "predictor.content_type = 'application/binary'\n",
    "predictor.serializer = None\n",
    "predictor.deserializer = None\n",
    "\n",
    "sentence1=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "sentence2=\"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    "sentence3=\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success. If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "cos = torch.nn.CosineSimilarity()\n",
    "\n",
    "encoded_sentence = tokenizer.encode_plus(sentence1, sentence3, max_length=128, pad_to_max_length=True, return_tensors=\"pt\", truncation=True)\n",
    "encoded_sentence_tuple = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids'] \n",
    "\n",
    "try:\n",
    "    pickled_bytes = pickle.dumps(encoded_sentence_tuple)\n",
    "    raw_bytes = predictor.predict(pickled_bytes)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "    \n",
    "#print(pickle.loads(raw_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "s_nouns = [\"A dude\", \"My mom\", \"The king\", \"Some guy\", \"A cat with rabies\", \"A sloth\", \"Your homie\", \"This cool guy my gardener met yesterday\", \"Superman\"]\n",
    "p_nouns = [\"These dudes\", \"Both of my moms\", \"All the kings of the world\", \"Some guys\", \"All of a cattery's cats\", \"The multitude of sloths living under your bed\", \"Your homies\", \"Like, these, like, all these people\", \"Supermen\"]\n",
    "s_verbs = [\"eats\", \"kicks\", \"gives\", \"treats\", \"meets with\", \"creates\", \"hacks\", \"configures\", \"spies on\", \"retards\", \"meows on\", \"flees from\", \"tries to automate\", \"explodes\"]\n",
    "p_verbs = [\"eat\", \"kick\", \"give\", \"treat\", \"meet with\", \"create\", \"hack\", \"configure\", \"spy on\", \"retard\", \"meow on\", \"flee from\", \"try to automate\", \"explode\"]\n",
    "infinitives = [\"to make a pie.\", \"for no apparent reason.\", \"because the sky is green.\", \"for a disease.\", \"to be able to make toast explode.\", \"to know more about archeology.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import boto3   \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "endpoint_name=predictor.endpoint\n",
    "total_runs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 inferences for bert-inf1-serving-2020-09-17-07-52-59-567:\n",
      "\n",
      "Errors - 0.0000 out of 1000.0000 total runs | 0.0000% \n",
      "\n",
      "Client end-to-end latency percentiles:\n",
      "Avg | P50 | P90 | P95 | P100\n",
      "27.5222 | 26.8953 | 29.5256 | 31.0617\n",
      "\n",
      "Getting Cloudwatch:\n",
      "Time elapsed: 327.524155 seconds\n",
      "Using period of 360 seconds\n",
      "\n",
      "Waiting 30 seconds ...\n",
      "206.0 latency datapoints ready\n",
      "Avg | P50 | P90 | P95 | P100\n",
      "19.5647 | 19.4170 | 21.4780 | 22.5970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Running {} inferences for {}:'.format(total_runs, endpoint_name))\n",
    "\n",
    "client_times = []\n",
    "errors_list = []\n",
    "cw_start = datetime.datetime.utcnow()\n",
    "\n",
    "errors = 0\n",
    "\n",
    "for i in range(total_runs):    \n",
    "    \n",
    "    client_start = time.time()\n",
    "    \n",
    "    sentence_random = (random.choice(s_nouns) + ' ' + random.choice(s_verbs) + ' ' + random.choice(s_nouns).lower() or random.choice(p_nouns).lower() + ' ' + random.choice(infinitives))\n",
    "    encoded_sentence = tokenizer.encode_plus(sentence1, sentence_random, max_length=128, pad_to_max_length=True, return_tensors=\"pt\", truncation=True)\n",
    "    encoded_sentence_tuple = encoded_sentence['input_ids'], encoded_sentence['attention_mask'], encoded_sentence['token_type_ids'] \n",
    "    \n",
    "    pickled_bytes = pickle.dumps(encoded_sentence_tuple)\n",
    "\n",
    "    try:\n",
    "        raw_bytes = predictor.predict(pickled_bytes)\n",
    "        errors_list.append(20)\n",
    "    except:\n",
    "        errors += 1\n",
    "        errors_list.append(30)\n",
    "        pass\n",
    "    \n",
    "    client_end = time.time()\n",
    "    client_times.append((client_end - client_start)*1000)\n",
    "    \n",
    "print('\\nErrors - {:.4f} out of {:.4f} total runs | {:.4f}% \\n'.format(errors, total_runs, (errors/total_runs)*100))\n",
    "errors = 0\n",
    "    \n",
    "    \n",
    "cw_end = datetime.datetime.utcnow()    \n",
    "    \n",
    "print('Client end-to-end latency percentiles:')\n",
    "client_avg = np.mean(client_times)\n",
    "client_p50 = np.percentile(client_times, 50)\n",
    "client_p90 = np.percentile(client_times, 90)\n",
    "client_p95 = np.percentile(client_times, 95)\n",
    "client_p100 = np.percentile(client_times, 100)\n",
    "print('Avg | P50 | P90 | P95 | P100')\n",
    "print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(client_avg, client_p50, client_p90, client_p95, client_p100))\n",
    "\n",
    "print('Getting Cloudwatch:')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "statistics=['SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "extended=['p50', 'p90', 'p95', 'p100']\n",
    "\n",
    "# Give 5 minute buffer to end\n",
    "cw_end += datetime.timedelta(minutes=5)\n",
    "\n",
    "# Period must be 1, 5, 10, 30, or multiple of 60\n",
    "# Calculate closest multiple of 60 to the total elapsed time\n",
    "factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "period = factor * 60\n",
    "print('Time elapsed: {} seconds'.format((cw_end - cw_start).total_seconds()))\n",
    "print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "cloudwatch_ready = False\n",
    "# Keep polling CloudWatch metrics until datapoints are available\n",
    "while not cloudwatch_ready:\n",
    "  time.sleep(30)\n",
    "  print('Waiting 30 seconds ...')\n",
    "  # Must use default units of microseconds\n",
    "  model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='ModelLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': endpoint_name},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  # Should be 1000\n",
    "  if len(model_latency_metrics['Datapoints']) > 0:\n",
    "    print('{} latency datapoints ready'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "    side_avg = model_latency_metrics['Datapoints'][0]['Average'] / total_runs\n",
    "    side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / total_runs\n",
    "    side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / total_runs\n",
    "    side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / total_runs\n",
    "    side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / total_runs\n",
    "    print('Avg | P50 | P90 | P95 | P100')\n",
    "    print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p100))\n",
    "\n",
    "    cloudwatch_ready = True\n",
    "    \n",
    "    #embeddings_returned = pickle.loads(raw_bytes)\n",
    "    #s1 = embeddings_returned[1]\n",
    "    #print(pickle.loads(raw_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
